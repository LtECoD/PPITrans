{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys/anaconda3/envs/workspace/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import XLNetModel, XLNetTokenizer\n",
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "\n",
    "\n",
    "def build_pretrained_model(model_name):\n",
    "    if \"t5\" in model_name:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "        model = T5EncoderModel.from_pretrained(model_name)\n",
    "    elif \"albert\" in model_name:\n",
    "        tokenizer = AlbertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "        model = AlbertModel.from_pretrained(model_name)\n",
    "    elif \"bert\" in model_name:\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "        model = BertModel.from_pretrained(model_name)\n",
    "    elif \"xlnet\" in model_name:\n",
    "        tokenizer = XLNetTokenizer.from_pretrained(model_name, do_lower_case=False )\n",
    "        model = XLNetModel.from_pretrained(model_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Unkown model name: {model_name}\")\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppm = \"Rostlab/prot_t5_xl_uniref50\"\n",
    "device = 0\n",
    "\n",
    "tokenizer, embeder = build_pretrained_model(ppm)\n",
    "embeder = embeder.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = open(\"train.seq\", \"r\").readlines()\n",
    "test_lines = open(\"test.seq\", \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, line in tqdm(enumerate(train_lines+test_lines)):\n",
    "    _id, seq, _ = line.strip().split()\n",
    "    seqs = [\" \".join(seq.strip())]\n",
    "    inputs = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=True)\n",
    "    inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n",
    "    seq_len = (inputs['attention_mask'][0] == 1).sum()\n",
    "    with torch.no_grad():\n",
    "        embedding = embeder(**inputs)\n",
    "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "    assert embedding.shape[0] == 1\n",
    "    embedding = embedding[0, :seq_len-1]\n",
    "    assert embedding.shape[0] == len(seq)\n",
    "    np.save(f\"embs/{_id}.npy\", embedding)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d87a92dc5e820933ce1158afb1b057ba0389716ff9ef4f91230a9bbd9be5ff60"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('workspace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
